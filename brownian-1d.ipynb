{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brownian Motion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import torch\n",
    "from pygsig.graph import StaticGraphTemporalSignal\n",
    "import torch_geometric.transforms as T\n",
    "from pygsig.signature import SignatureFeatures, StatFeatures\n",
    "\n",
    "class Simulation():\n",
    "    def __init__( self,num_nodes,num_blocks, p_across_blocks,p_within_blocks, mu_gain,beta_gain,sigma_gain,omega_noise,time_horizon,dt = 1e-3):\n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_blocks = num_blocks\n",
    "        self.p_across_blocks = p_across_blocks\n",
    "        self.p_within_blocks = p_within_blocks\n",
    "        self.mu_gain = mu_gain\n",
    "        self.beta_gain = beta_gain\n",
    "        self.sigma_gain = sigma_gain\n",
    "        self.omega_noise = omega_noise\n",
    "        self.time_horizon = time_horizon\n",
    "        self.dt = dt\n",
    "        self.num_time_steps = int(time_horizon / dt)\n",
    "\n",
    "    def run(self,graph_seed,omega_seed,param_seed):\n",
    "\n",
    "        # synchronization\n",
    "        def kuramoto(graph, theta, omega, dt):\n",
    "            dtheta = omega * dt  # Initialize with intrinsic frequencies\n",
    "            for u, v, data in graph.edges(data=True):\n",
    "                coupling = data['weight']\n",
    "                dtheta[u] += dt * coupling * np.sin(theta[v] - theta[u])\n",
    "                dtheta[v] += dt * coupling * np.sin(theta[u] - theta[v])\n",
    "            return theta + dtheta\n",
    "\n",
    "        # drift of the SDE\n",
    "        def periodic_drift(beta, theta, omega, mu_0, t):\n",
    "            return mu_0 + beta*np.sin(omega*t + theta)\n",
    "\n",
    "        # Create a graph\n",
    "        block_sizes = [self.num_nodes // self.num_blocks] * self.num_blocks\n",
    "        block_probs = np.zeros((self.num_blocks, self.num_blocks))\n",
    "\n",
    "        for i in range(self.num_blocks):\n",
    "            for j in range(self.num_blocks):\n",
    "                if i == j:\n",
    "                    block_probs[i, j] = self.p_within_blocks\n",
    "                else:\n",
    "                    block_probs[i, j] = self.p_across_blocks\n",
    "        \n",
    "        graph = nx.stochastic_block_model(block_sizes, block_probs, seed=graph_seed)\n",
    "\n",
    "        for edge in graph.edges:\n",
    "            if graph.nodes[edge[0]]['block'] == graph.nodes[edge[1]]['block']:\n",
    "                graph[edge[0]][edge[1]]['weight'] = 1/(np.sqrt(graph.degree[edge[0]]*graph.degree[edge[1]]))\n",
    "            else:\n",
    "                graph[edge[0]][edge[1]]['weight'] = 1/(np.sqrt(graph.degree[edge[0]]*graph.degree[edge[1]]))\n",
    "        \n",
    "        # Assign omega to each node\n",
    "        np.random.seed(omega_seed)\n",
    "        omega_range = np.linspace(0,1, self.num_blocks+1)[1:]\n",
    "        for node in graph.nodes:\n",
    "            graph.nodes[node]['omega'] = omega_range[graph.nodes[node]['block']] + self.omega_noise * np.random.randn()\n",
    "        \n",
    "        # Othe oscilator perameters\n",
    "        np.random.seed(param_seed)\n",
    "        omega = np.array([graph.nodes[node]['omega'] for node in graph.nodes])\n",
    "        beta =  self.beta_gain * np.random.rand(self.num_nodes) # amplitude (uniform nodes)\n",
    "        theta = 2 * np.pi * np.random.rand(self.num_nodes)  # initial phase (random across nodes)\n",
    "        mu_0 = self.mu_gain * np.random.rand(self.num_nodes)\n",
    "\n",
    "        # initial values\n",
    "        X = np.random.rand(self.num_nodes) # signal\n",
    "\n",
    "        # Simulate\n",
    "        theta_traj = np.zeros((self.num_nodes,self.num_time_steps))\n",
    "        mu_traj = np.zeros((self.num_nodes,self.num_time_steps))\n",
    "        X_traj = np.zeros((self.num_nodes,self.num_time_steps))\n",
    "\n",
    "        # Time sequence\n",
    "        tt = np.arange(0, self.time_horizon, self.dt)\n",
    "        for step,t in enumerate(tt):\n",
    "            theta_traj[:, step] = theta\n",
    "            if step == 0:\n",
    "                mu_traj[:,step] = mu_0\n",
    "            else:\n",
    "                mu_traj[:,step] = mu\n",
    "            X_traj[:,step] = X\n",
    "            theta = kuramoto(graph, theta, omega,self.dt)\n",
    "            mu = periodic_drift(beta, theta,omega, mu_0, t)\n",
    "            X = X + self.dt * mu + np.sqrt(self.dt) * self.sigma_gain*np.random.randn(self.num_nodes)\n",
    "\n",
    "        return X_traj, theta_traj, mu_traj, omega, mu_0, beta,  graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence(X_traj,graph):\n",
    "    snapshot_count = X_traj.shape[1]\n",
    "    df_edge = nx.to_pandas_edgelist(graph.to_directed())\n",
    "    edge_index = torch.tensor(df_edge[['source','target']].values.T,dtype=torch.long)\n",
    "    edge_weight = torch.tensor(df_edge['weight'].values,dtype=torch.float)\n",
    "    snapshot_count = X_traj.shape[1]\n",
    "    features = [ torch.tensor(X_traj[:,t],dtype=torch.float).unsqueeze(-1) for t in range(snapshot_count)]\n",
    "    targets = [ torch.tensor(np.array([graph.nodes[node]['omega'] for node in graph.nodes]),dtype=torch.float).unsqueeze(-1) for _ in range(snapshot_count)]\n",
    "    # Sequential Data\n",
    "    return StaticGraphTemporalSignal(edge_index=edge_index,edge_weight=edge_weight,features=features,targets=targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "simulation =   Simulation(num_nodes= 20,\n",
    "                num_blocks=2,\n",
    "                p_across_blocks=0.1,\n",
    "                p_within_blocks=0.5,\n",
    "                mu_gain= 1.0,\n",
    "                beta_gain=5.0,\n",
    "                sigma_gain=1.0,\n",
    "                omega_noise=0.1,\n",
    "                time_horizon=10,\n",
    "                dt=1e-3)\n",
    "\n",
    "X_traj, theta_traj, mu_traj, omega, mu_0, beta, graph = simulation.run(graph_seed=32,omega_seed=29,param_seed=29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the block information for each node\n",
    "blocks = nx.get_node_attributes(graph, 'block')\n",
    "\n",
    "# Create a color map for the blocks\n",
    "unique_blocks = list(set(blocks.values()))\n",
    "colors = ['#012169','#4B9CD3']\n",
    "block_color_map = {block: colors[i] for i, block in enumerate(unique_blocks)}\n",
    "\n",
    "# Assign colors to nodes based on their block\n",
    "node_colors = [block_color_map[blocks[node]] for node in graph.nodes]\n",
    "\n",
    "# Draw the graph\n",
    "plt.figure(figsize=(4, 4),dpi=200)\n",
    "nx.draw(graph, node_color=node_colors,pos=nx.circular_layout(graph), node_size=100, font_size=10, font_color='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "norm = mcolors.Normalize(vmin=0, vmax=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4),dpi=200)\n",
    "cmap = cm.get_cmap('Spectral')\n",
    "\n",
    "\n",
    "for node in range(simulation.num_nodes):\n",
    "    sns.lineplot(x=np.linspace(0, simulation.time_horizon, simulation.num_time_steps), \n",
    "                 y=X_traj[node, :], \n",
    "                 color=block_color_map[blocks[node]], \n",
    "                 ax=ax)\n",
    "\n",
    "# Create ScalarMappable for colorbar\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "\n",
    "plt.xlabel('$t$')\n",
    "plt.ylabel('$X$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make dataset consisting of multiple SDE trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "simulation =   Simulation(num_nodes= 300,\n",
    "            num_blocks=3,\n",
    "            p_across_blocks=0.01,\n",
    "            p_within_blocks=0.1,\n",
    "            mu_gain= 1,\n",
    "            beta_gain=4,\n",
    "            sigma_gain=1.0,\n",
    "            omega_noise=0.0,\n",
    "            time_horizon=10,\n",
    "            dt=1e-3)\n",
    "\n",
    "\n",
    "\n",
    "seq_dataset = []\n",
    "num_runs = 20\n",
    "\n",
    "with tqdm(total=num_runs) as pbar:\n",
    "    for run in range(num_runs):\n",
    "        paths, theta, mu, omega, mu_0, beta, graph = simulation.run(graph_seed=run,omega_seed=run,param_seed=run)\n",
    "        seq = get_sequence(paths,graph)\n",
    "        seq_dataset.append(seq)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save/load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "filename = 'datasets/brownian/brownian-1d-3b.pt'\n",
    "# torch.save(seq_dataset,filename)\n",
    "seq_dataset = torch.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train, baby, train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch_geometric.transforms as T\n",
    "from signatory import signature_channels\n",
    "\n",
    "\n",
    "import pygsig.graph \n",
    "import pygsig.models\n",
    "import pygsig.signature\n",
    "from pygsig.models import GCNRegression, MLPRegression\n",
    "from pygsig.graph import  split_nodes\n",
    "\n",
    "import importlib\n",
    "importlib.reload(pygsig.models)\n",
    "importlib.reload(pygsig.signature)\n",
    "importlib.reload(pygsig.graph)\n",
    "\n",
    "num_nodes = seq_dataset[0].num_nodes\n",
    "dim = seq_dataset[0].num_node_features\n",
    "out_channels = 1\n",
    "num_splits = 5 # split the nodes\n",
    "num_runs = len(seq_dataset)\n",
    "num_trials = 4\n",
    "num_epochs = 200\n",
    "\n",
    "# hyperparameters\n",
    "learning_rate = 1e-3\n",
    "lasso = 0\n",
    "num_hidden = 64\n",
    "\n",
    "print_during_training = False\n",
    "\n",
    "all_models = []\n",
    "all_model_parameters = []\n",
    "all_model_depths = []\n",
    "all_model_layers = []\n",
    "all_models_mse = []\n",
    "all_models_mae = []\n",
    "all_models_rmse = []\n",
    "\n",
    "# create models \n",
    "max_depth = 5\n",
    "max_layers = 5\n",
    "for depth in range(1,max_depth+1):\n",
    "    print(f'Signature depth: {depth}')\n",
    "    dataset = []\n",
    "    for seq in tqdm(seq_dataset):\n",
    "        signature_transform = SignatureFeatures(sig_depth=depth, normalize=True, log_signature=False,lead_lag=True)\n",
    "        dataset.append(signature_transform(seq))\n",
    "    for num_layers in range(max_layers):\n",
    "        in_channels = signature_channels(2*dim,depth)\n",
    "        model = GCNRegression(num_channels=[in_channels]+num_layers*[num_hidden]+[out_channels])\n",
    "        num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        print(f'Name: {model._get_name()}')\n",
    "        print(f\"Number of parameters: {num_params}\")\n",
    "        print(f\"Number of layers: {num_layers+1}\")\n",
    "        print(f\"Signature depth: {depth}\")\n",
    "        print(f\"Splits: {num_splits}, Trials: {num_trials}, Runs: {num_runs}, Epochs: {num_epochs}\")\n",
    "        all_model_parameters.append(num_params)\n",
    "        all_model_layers.append(num_layers+1)\n",
    "        all_model_depths.append(depth)\n",
    "        \n",
    "        criterion = nn.MSELoss() # loss function\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,weight_decay=lasso) \n",
    "        train_losses = np.zeros([num_splits, num_runs, num_trials, num_epochs]) \n",
    "        eval_losses = np.zeros([num_splits, num_runs, num_trials, num_epochs])\n",
    "        mse = np.zeros([num_splits, num_runs, num_trials])\n",
    "        mae = np.zeros([num_splits, num_runs, num_trials])\n",
    "        rmse = np.zeros([num_splits, num_runs, num_trials])\n",
    "\n",
    "        with tqdm(total=num_splits*num_runs*num_trials, disable=print_during_training) as pbar:\n",
    "            splits = split_nodes(num_nodes, num_splits,test_ratio=1.0,seed=29)\n",
    "            for split in range(num_splits):\n",
    "                train_indices, eval_indices, test_indices = splits[split]\n",
    "                train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "                eval_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "                test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "                train_mask[train_indices] = True\n",
    "                eval_mask[eval_indices] = True\n",
    "                test_mask[test_indices] = True\n",
    "                for run, data in enumerate(dataset):\n",
    "                    for trial in range(num_trials):\n",
    "                        model.reset_parameters()\n",
    "                        for epoch in range(num_epochs):\n",
    "                            # train\n",
    "                            model.train()\n",
    "                            optimizer.zero_grad()\n",
    "                            out = model(data.x, data.edge_index)\n",
    "                            train_loss = criterion(out[train_mask], data.y[train_mask])\n",
    "                            train_loss.backward()\n",
    "                            optimizer.step()\n",
    "                            # evaluate\n",
    "                            model.eval()\n",
    "                            with torch.no_grad():\n",
    "                                eval_loss = criterion(out[eval_mask], data.y[eval_mask])\n",
    "                                train_losses[split, run, trial, epoch] = train_loss.item()\n",
    "                                eval_losses[split, run, trial, epoch] = eval_loss.item()\n",
    "                            if epoch % 10 == 0 and print_during_training:\n",
    "                                print(f'Split {split}, Run {run}, Trial {trial}, Epoch {epoch}, Train MSE Loss: {train_loss.item():.4f}, Evaulation MSE Loss: {eval_loss.item():.4f}')\n",
    "                        pbar.update(1)\n",
    "                        # compute the errors on the testing loss after the last epoch\n",
    "                        with torch.no_grad():\n",
    "                            out = model(data.x, data.edge_index)\n",
    "                            mse[split, run, trial] = mean_squared_error(data.y[test_mask], out[test_mask])\n",
    "                            mae[split, run, trial] = mean_absolute_error(data.y[test_mask], out[test_mask])\n",
    "                            rmse[split, run, trial] = np.sqrt(mean_squared_error(data.y[test_mask], out[test_mask]))\n",
    "\n",
    "        print(f'MSE: {np.mean(mse):.4f} ± {np.std(mse):.4f}, MAE: {np.mean(mae):.4f} ± {np.std(mae):.4f}, RMSE: {np.mean(rmse):.4f} ± {np.std(rmse):.4f}')  \n",
    "        all_models_mse.append(mse)\n",
    "        all_models_mae.append(mae)\n",
    "        all_models_rmse.append(rmse)\n",
    "\n",
    "        # Plotting\n",
    "        avg_train_losses = np.mean(train_losses, axis=(0,1,2))\n",
    "        avg_eval_losses = np.mean(eval_losses, axis=(0,1,2))\n",
    "        std_train_losses = np.std(train_losses, axis=(0,1,2))\n",
    "        std_eval_losses = np.std(eval_losses, axis=(0,1,2))\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.plot(avg_train_losses,  label='Train Loss', color='maroon')\n",
    "        # plt.plot(avg_eval_losses,  label='Evaluation Loss', color='navy')\n",
    "        plt.fill_between(range(num_epochs), avg_train_losses - std_train_losses, avg_train_losses + std_train_losses, alpha=0.1, color='maroon')\n",
    "        # plt.fill_between(range(num_epochs), avg_eval_losses - std_eval_losses, avg_eval_losses + std_eval_losses, alpha=0.1,color='navy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('MSE Loss')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe with all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Collecting data in a list of dictionaries\n",
    "data = []\n",
    "# Populate the data list\n",
    "for idx,model in enumerate(all_models):\n",
    "    for split in range(num_splits):\n",
    "        for run in range(num_runs):\n",
    "            for trial in range(num_trials):\n",
    "                # Extract MAE and RMSE for the current model, split, and run\n",
    "                mae_value = all_models_mae[idx][split, run, trial]\n",
    "                mse_value = all_models_mse[idx][split, run, trial]\n",
    "                rmse_value = all_models_rmse[idx][split, run, trial]\n",
    "                num_layers = all_model_layers[idx]\n",
    "                depth = all_model_depths[idx]\n",
    "                num_params = all_model_parameters[idx]\n",
    "                \n",
    "                # Append the data as a dictionary\n",
    "                data.append({\n",
    "                    'SigDepth': depth,\n",
    "                    'NumLayers': num_layers,\n",
    "                    'NumParams': num_params,\n",
    "                    'Split': split,\n",
    "                    'Run': run,\n",
    "                    'Trial': trial,\n",
    "                    'MAE': mae_value,\n",
    "                    'MSE': mse_value,\n",
    "                    'RMSE': rmse_value\n",
    "                })\n",
    "\n",
    "# Create the DataFrame from the list of dictionaries\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Recurrent Convolutional Neutral Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import signatory\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "\n",
    "import pygsig.graph \n",
    "import pygsig.models\n",
    "import pygsig.signature\n",
    "from pygsig.models import GConvGRURegression,GConvLSTMRegression\n",
    "from pygsig.graph import StaticGraphTemporalSignal, split_nodes\n",
    "from pygsig.signature import SignatureFeatures\n",
    "\n",
    "import importlib\n",
    "importlib.reload(pygsig.models)\n",
    "importlib.reload(pygsig.signature)\n",
    "importlib.reload(pygsig.graph)\n",
    "\n",
    "num_splits = 5\n",
    "num_runs = len(seq_dataset)\n",
    "num_trials = 1\n",
    "num_epochs = 10\n",
    "num_nodes = seq_dataset[0].num_nodes\n",
    "dim = seq_dataset[0].num_node_features\n",
    "sample_rate = 100 # only take every 'sample_rate' snapshots\n",
    "num_snapshots = seq_dataset[0].snapshot_count//sample_rate\n",
    "\n",
    "learning_rate = 1e-3\n",
    "lasso = 0\n",
    "num_hidden = 64\n",
    "\n",
    "print_during_training = True\n",
    "\n",
    "# initialize models\n",
    "models = []\n",
    "models += [GConvGRURegression(num_channels=[dim, num_hidden, 1],K=3)]\n",
    "models += [GConvLSTMRegression(num_channels=[dim, num_hidden, 1],K=3)]\n",
    "\n",
    "mse_models = []\n",
    "mae_models = []\n",
    "rmse_models = []\n",
    "\n",
    "for model in models:\n",
    "    print(f'Model: {model._get_name()}')\n",
    "    print(f\"Number of parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,weight_decay=lasso)\n",
    "    train_losses = np.zeros([num_splits, num_runs, num_trials, num_epochs,num_snapshots])\n",
    "    eval_losses = np.zeros([num_splits, num_runs, num_trials, num_epochs,num_snapshots])\n",
    "    mse = np.zeros([num_splits, num_runs, num_trials])\n",
    "    mae = np.zeros([num_splits, num_runs, num_trials])\n",
    "    rmse = np.zeros([num_splits, num_runs, num_trials])\n",
    "\n",
    "    with tqdm(total=num_splits*num_runs*num_trials, disable=print_during_training) as pbar:\n",
    "        splits = split_nodes(num_nodes, num_splits,test_ratio=1.0,seed=29)\n",
    "        for split in range(num_splits):\n",
    "            train_indices, eval_indices, test_indices = splits[split]\n",
    "            train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "            eval_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "            test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "            train_mask[train_indices] = True\n",
    "            eval_mask[eval_indices] = True\n",
    "            test_mask[test_indices] = True\n",
    "            for run, full_seq in enumerate(seq_dataset):\n",
    "                seq = StaticGraphTemporalSignal(edge_index=full_seq.edge_index,edge_weight=full_seq.edge_weight,features=full_seq.features[::sample_rate],targets=full_seq.targets[::sample_rate])\n",
    "                for trial in range(num_trials):\n",
    "                    model.reset_parameters()\n",
    "                    for epoch in range(num_epochs):\n",
    "                        for t,snapshot in enumerate(seq):\n",
    "                            # train\n",
    "                            model.train()\n",
    "                            optimizer.zero_grad()\n",
    "                            out = model(snapshot.x, snapshot.edge_index)\n",
    "                            train_loss = criterion(out[train_mask], snapshot.y[train_mask])\n",
    "                            train_loss.backward()\n",
    "                            optimizer.step()\n",
    "                            # evaluate\n",
    "                            model.eval()\n",
    "                            with torch.no_grad():\n",
    "                                eval_loss = criterion(out[eval_mask], snapshot.y[eval_mask])\n",
    "                                train_losses[split, run, trial, epoch,t] = train_loss.item()\n",
    "                                eval_losses[split, run, trial, epoch,t] = eval_loss.item()\n",
    "                        if print_during_training:\n",
    "                            print(f'Split {split}, Run {run}, Trial {trial}, Epoch {epoch}, Train MSE Loss: {train_loss.item():.4f}')\n",
    "                    pbar.update(1)\n",
    "\n",
    "                    # compute the errors on the testing loss after the last epoch\n",
    "                    with torch.no_grad():\n",
    "                        out = model(snapshot.x, snapshot.edge_index)\n",
    "                        mse[split, run, trial] = mean_squared_error(snapshot.y[test_mask], out[test_mask])\n",
    "                        mae[split, run, trial] = mean_absolute_error(snapshot.y[test_mask], out[test_mask])\n",
    "                        rmse[split, run, trial] = np.sqrt(mean_squared_error(snapshot.y[test_mask], out[test_mask]))\n",
    "\n",
    "    print(f'MSE: {np.mean(mse):.4f} ± {np.std(mse):.4f}, MAE: {np.mean(mae):.4f} ± {np.std(mae):.4f}, RMSE: {np.mean(rmse):.4f} ± {np.std(rmse):.4f}')  \n",
    "    mse_models.append(mse)\n",
    "    mae_models.append(mae)\n",
    "    rmse_models.append(rmse)\n",
    "\n",
    "\n",
    "    # Plotting\n",
    "    avg_train_losses = np.mean(train_losses, axis=(0,1,2,-1))\n",
    "    avg_eval_losses = np.mean(eval_losses, axis=(0,1,2,-1))\n",
    "    std_train_losses = np.std(train_losses, axis=(0,1,2,-1))\n",
    "    std_eval_losses = np.std(eval_losses, axis=(0,1,2,-1))\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(avg_train_losses,  label='Train Loss', color='maroon')\n",
    "    # plt.plot(avg_eval_losses,  label='Evaluation Loss', color='navy')\n",
    "    plt.fill_between(range(num_epochs), avg_train_losses - std_train_losses, avg_train_losses + std_train_losses, alpha=0.1, color='maroon')\n",
    "    # plt.fill_between(range(num_epochs), avg_eval_losses - std_eval_losses, avg_eval_losses + std_eval_losses, alpha=0.1,color='navy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
